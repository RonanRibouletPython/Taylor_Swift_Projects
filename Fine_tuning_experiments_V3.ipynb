{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will:\n",
    "- Use Albumentations to create a new augmented datasets with thousands of augmented images\n",
    "- Fine tune the EfficientNetV2 model for maximum F1 score and the final deployment of the model to our website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMAGE_SIZE = 384\n",
    "BATCH_SIZE = 8\n",
    "CHANNELS= 3\n",
    "ES_EPOCHS = 20 \n",
    "CLASSES = 10\n",
    "EPOCHS= 200\n",
    "SAMPLES_AUG_IMG = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"1989\", \"Acoustic\", \"Fearless\", \"Folkmore\", \"Lover\", \"Midnights\", \"Red\", \"Reputation\", \"Speak Now\", \"TTPD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_directory = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/train\"\n",
    "\n",
    "# Val\n",
    "val_directory = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/val\"\n",
    "\n",
    "# Test\n",
    "test_directory = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation pipeline using Albumentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images_App_Test/1989_orange.jpeg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "visualize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "            A.Rotate(limit=40),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "            A.HorizontalFlip(),\n",
    "            A.ShiftScaleRotate(p=0.5),\n",
    "            A.Blur(blur_limit=3),\n",
    "            A.OpticalDistortion(),\n",
    "            A.GridDistortion(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import albumentations as A\n",
    "\n",
    "# Define paths\n",
    "dataset_path = 'train'  # Replace with your dataset path\n",
    "augmented_dataset_path = 'augmented_train'  # Replace with desired output path\n",
    "\n",
    "# Define augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),              # Horizontal flip with 50% probability\n",
    "    A.VerticalFlip(p=0.5),                # Vertical flip with 50% probability\n",
    "    A.RandomRotate90(p=0.5),              # Random 90-degree rotation with 50% probability\n",
    "    A.RandomBrightnessContrast(p=0.5),      # Random brightness/contrast adjustments\n",
    "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),  # Random shift, scale, and rotation\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),  # Random hue, saturation, and value adjustments\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # Gaussian blur with random kernel size\n",
    "], p=1.0)  # Apply the entire pipeline with probability 1.0\n",
    "\n",
    "# Function to augment images in a directory\n",
    "def augment_images(source_dir, dest_dir, num_augmentations=SAMPLES_AUG_IMG):\n",
    "    \"\"\"\n",
    "    Augments images in a source directory and saves them to a destination directory.\n",
    "\n",
    "    Args:\n",
    "        source_dir (str): Path to the directory containing the original images.\n",
    "        dest_dir (str): Path to the directory where augmented images will be saved.\n",
    "        num_augmentations (int): Number of augmentations to generate per image.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(source_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            for i in range(num_augmentations):\n",
    "                augmented_image = transform(image=image)['image']\n",
    "                augmented_filename = f\"{os.path.splitext(filename)[0]}_aug_{i}.jpg\"\n",
    "                augmented_path = os.path.join(dest_dir, augmented_filename)\n",
    "                cv2.imwrite(augmented_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Create the augmented dataset directory structure\n",
    "if not os.path.exists(augmented_dataset_path):\n",
    "    os.makedirs(augmented_dataset_path)\n",
    "\n",
    "# Iterate through classes and augment images\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_source_dir = os.path.join(dataset_path, class_name)\n",
    "    class_dest_dir = os.path.join(augmented_dataset_path, class_name)\n",
    "    if not os.path.exists(class_dest_dir):\n",
    "        os.makedirs(class_dest_dir)\n",
    "    augment_images(class_source_dir, class_dest_dir)\n",
    "\n",
    "print(\"Data augmentation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the images\n",
    "test_dir = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/test\"\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    seed=42,\n",
    "    label_mode='int',\n",
    "    validation_split=None,\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the images\n",
    "train_dir = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/augmented_train\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    seed = 42,\n",
    "    label_mode='int',\n",
    "    validation_split=None,\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the images\n",
    "val_dir = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/val\"\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels='inferred',\n",
    "    seed = 42,\n",
    "    label_mode='int',\n",
    "    validation_split=None,\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "    ----------------------------------\n",
    "    Dataset split:\n",
    "        - train split: {len(train_ds)}\n",
    "        - val split: {len(val_ds)}\n",
    "        - test split: {len(test_ds)}\n",
    "    ----------------------------------\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caching the dataset\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "main_folder = 'augmented_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_counts = {}\n",
    "\n",
    "# Iterate through each subfolder (era)\n",
    "for era_folder in os.listdir(main_folder):\n",
    "    era_path = os.path.join(main_folder, era_folder)\n",
    "    if os.path.isdir(era_path):\n",
    "        # Count the number of images in the era folder\n",
    "        era_counts[era_folder] = len([filename for filename in os.listdir(era_path) if filename.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "# Create a pandas DataFrame from the era_counts dictionary\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Era': era_counts.keys(), 'Image Count': era_counts.values()})\n",
    "\n",
    "# Create the bar plot using seaborn\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "ax = sns.barplot(x='Era', y='Image Count', data=df, palette='flare')  # Choose a color palette you like\n",
    "for bar in range(len(ax.containers)):\n",
    "    ax.bar_label(ax.containers[bar])\n",
    "# Customize the plot\n",
    "plt.title('Data Imbalance in Taylor Swift Eras Tour Images', fontsize=16)\n",
    "plt.xlabel('Eras', fontsize=14)\n",
    "plt.ylabel('Number of Images', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_inverse_num_samples(num_of_classes, samples_per_classes, coeff=1):\n",
    "    \"\"\"\n",
    "    Get the inverse number of samples for each class.\n",
    "    Args:\n",
    "        num_of_classes (int): Number of classes in the dataset.\n",
    "        samples_per_classes (list): List of number of samples per class.\n",
    "        power (int, optional): Power of the inverse number of samples. Defaults to 1.\n",
    "    Returns:\n",
    "        list: List of inverse number of samples for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    inverse_num_samples = []\n",
    "    total_samples = sum(samples_per_classes)\n",
    "\n",
    "    for i in range(num_of_classes):\n",
    "        inverse_num_samples.append((total_samples / (num_of_classes * samples_per_classes[i])) * coeff)\n",
    "\n",
    "    return inverse_num_samples\n",
    "\n",
    "num_of_classes = 10\n",
    "samples_per_classes = [era_counts['1989'], era_counts['Acoustic'], era_counts['Fearless'], era_counts['Folkmore'], era_counts['Lover'], era_counts['Midnights'], era_counts['Red'], era_counts['Reputation'], era_counts['Speak Now'], era_counts['TTPD']] \n",
    "\n",
    "weighted_classes = get_weight_inverse_num_samples(num_of_classes, samples_per_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indexes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dict(zip(class_indexes, weighted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = tf.keras.applications.EfficientNetV2S(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in conv_base.layers[:-8]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "\n",
    "x = tf.keras.applications.efficientnet_v2.preprocess_input(inputs)\n",
    "\n",
    "# The output of the base model is taken as the input for the new model\n",
    "x = conv_base(x)\n",
    "# This layer averages the spatial dimensions (height and width) of the output from the previous layer\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# Add a Dense layer with 512 units and 'relu' activation function to the model\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "# This layer randomly sets a fraction of input units to 0 at each update during training time, which helps prevent overfitting\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# This layer will output the probabilities for the 10 classes\n",
    "outputs = tf.keras.layers.Dense(CLASSES, activation=\"softmax\", kernel_regularizer=l2(0.001))(x)\n",
    "\n",
    "#outputs = tf.keras.layers.Dense(CLASSES, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"saved_models/all_VGG16_models/best_model_weighted_RESNET50_getty_aug.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "lr_plateau = callbacks.ReduceLROnPlateau(factor=0.8, monitor=\"val_accuracy\", patience=5, verbose=1)\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=ES_EPOCHS)\n",
    "callbacks_list = [checkpoint, es, lr_plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=weights\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
