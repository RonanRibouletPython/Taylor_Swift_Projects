{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that our best model is made with the VGG16 pretrained model we can use a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "CHANNELS= 3\n",
    "ES_EPOCHS = 10 \n",
    "CLASSES = 10\n",
    "EPOCHS= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"1989\", \"Acoustic\", \"Fearless\", \"Folkmore\", \"Lover\", \"Midnights\", \"Red\", \"Reputation\", \"Speak Now\", \"TTPD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset(folder_path, output_path, train_split=0.8, test_split=0.1, \n",
    "                   val_split=0.1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the images in the given folder into train, test, and validation sets,\n",
    "    and moves them to the specified output path, ensuring no duplicate moves.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing the images.\n",
    "        output_path (str): Path to the directory where the split datasets \n",
    "                          will be saved.\n",
    "        train_split (float, optional): Ratio of images for training (0.0 to 1.0). \n",
    "                                     Defaults to 0.8.\n",
    "        test_split (float, optional): Ratio of images for testing (0.0 to 1.0). \n",
    "                                    Defaults to 0.1.\n",
    "        val_split (float, optional): Ratio of images for validation (0.0 to 1.0). \n",
    "                                    Defaults to 0.1.\n",
    "        shuffle (bool, optional): Whether to shuffle the images. Defaults to True.\n",
    "        shuffle_size (int, optional): Size of the shuffle buffer. Defaults to 1000.\n",
    "    \"\"\"\n",
    "\n",
    "    if train_split + test_split + val_split != 1.0:\n",
    "        raise ValueError(\"Train, test, and validation splits must add up to 1.0\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Create subfolders for train, test, and validation in the output directory\n",
    "    for subfolder in [\"train\", \"test\", \"val\"]:\n",
    "        os.makedirs(os.path.join(output_path, subfolder), exist_ok=True)\n",
    "\n",
    "    # Get list of image files in the folder\n",
    "    image_files = [\n",
    "        f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))\n",
    "    ]\n",
    "\n",
    "    # Shuffle the image files\n",
    "    if shuffle:\n",
    "        random.shuffle(image_files)\n",
    "\n",
    "    # Calculate the number of images for each set\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(num_images * train_split)\n",
    "    num_test = int(num_images * test_split)\n",
    "\n",
    "    # Split the image files into sets\n",
    "    train_files = image_files[:num_train]\n",
    "    test_files = image_files[num_train : num_train + num_test]\n",
    "    val_files = image_files[num_train + num_test :]\n",
    "\n",
    "    # Move images to corresponding subfolders, preventing duplicates\n",
    "    for file_list, subfolder in zip(\n",
    "        [train_files, test_files, val_files], [\"train\", \"test\", \"val\"]\n",
    "    ):\n",
    "        for image_file in file_list:\n",
    "            src_path = os.path.join(folder_path, image_file)\n",
    "            dest_path = os.path.join(output_path, subfolder, image_file)\n",
    "            if not os.path.exists(dest_path):  # Check if file already exists\n",
    "                shutil.move(src_path, dest_path) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_images(directory):\n",
    "  \"\"\"Organizes images in a directory into subfolders based on the first word of their filenames.\n",
    "\n",
    "  Args:\n",
    "    directory: The path to the directory containing the images.\n",
    "  \"\"\"\n",
    "\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png', '.gif')):  # Adjust file extensions if needed\n",
    "      file_path = os.path.join(directory, filename)\n",
    "      folder_name = filename.split('_')[0]  # Extract the first word before \"_\"\n",
    "      folder_path = os.path.join(directory, folder_name)\n",
    "\n",
    "      # Create the folder if it doesn't exist\n",
    "      if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "      # Move the image to the corresponding folder\n",
    "      shutil.move(file_path, os.path.join(folder_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\\"\n",
    "\n",
    "# 1989\n",
    "_1989_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\1989\"\n",
    "split_dataset(_1989_path, output_path) \n",
    "\n",
    "# Acoustic\n",
    "acoustic_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Acoustic\"\n",
    "split_dataset(acoustic_path, output_path) \n",
    "\n",
    "# Fearless\n",
    "fearless_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Fearless\"\n",
    "split_dataset(fearless_path, output_path)\n",
    "\n",
    "# Folkmore\n",
    "folkmore_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Folkmore\"\n",
    "split_dataset(folkmore_path, output_path)\n",
    "\n",
    "# Lover\n",
    "lover_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Lover\"\n",
    "split_dataset(lover_path, output_path)\n",
    "\n",
    "# Midnights\n",
    "midnights_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Midnights\"\n",
    "split_dataset(midnights_path, output_path)\n",
    "\n",
    "# Red\n",
    "red_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Red\"\n",
    "split_dataset(red_path, output_path)\n",
    "\n",
    "# Reputation\n",
    "reputation_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Reputation\"\n",
    "split_dataset(reputation_path, output_path)\n",
    "\n",
    "# Speak Now\n",
    "speak_now_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\Speak Now\"\n",
    "split_dataset(speak_now_path, output_path)\n",
    "\n",
    "# TTPD\n",
    "ttpd_path = \"C:\\\\Users\\\\Ronan\\\\Documents\\\\ML\\\\Taylor_Swift_Projects\\\\CNN\\\\Latest_TS_Dataset\\\\TTPD\"\n",
    "split_dataset(ttpd_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Ronan\\Documents\\ML\\Taylor_Swift_Projects\\CNN\\venv\\Lib\\shutil.py:886\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 886\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 87] Paramètre incorrect: 'C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/train\\\\gettyimages-1249661714-612x612.jpg' -> 'C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/train\\\\gettyimages-1249661714-612x612.jpg\\\\gettyimages-1249661714-612x612.jpg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43morganize_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Val\u001b[39;00m\n\u001b[0;32m      6\u001b[0m val_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/val\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m, in \u001b[0;36morganize_images\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     16\u001b[0m   os\u001b[38;5;241m.\u001b[39mmakedirs(folder_path)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Move the image to the corresponding folder\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ronan\\Documents\\ML\\Taylor_Swift_Projects\\CNN\\venv\\Lib\\shutil.py:906\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    904\u001b[0m         rmtree(src)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 906\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    907\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[1;32mc:\\Users\\Ronan\\Documents\\ML\\Taylor_Swift_Projects\\CNN\\venv\\Lib\\shutil.py:460\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    458\u001b[0m     flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCOPY_FILE_COPY_SYMLINK\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCopyFile2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train_directory = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/train\"\n",
    "organize_images(train_directory)\n",
    "\n",
    "# Val\n",
    "val_directory = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/val\"\n",
    "organize_images(val_directory)\n",
    "\n",
    "# Test\n",
    "test_directory = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/test\"\n",
    "organize_images(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the images\n",
    "test_dir = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/test\"\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    seed=42,\n",
    "    label_mode='int',\n",
    "    validation_split=None,\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the images\n",
    "train_dir = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/train\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    seed = 42,\n",
    "    label_mode='int',\n",
    "    validation_split=None,\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the images\n",
    "val_dir = \"C:/Users/Ronan/Documents/ML/Taylor_Swift_Projects/CNN/val\"\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels='inferred',\n",
    "    seed = 42,\n",
    "    label_mode='int',\n",
    "    validation_split=None,\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "    ----------------------------------\n",
    "    Dataset split:\n",
    "        - train split: {len(train_ds)}\n",
    "        - val split: {len(val_ds)}\n",
    "        - test split: {len(test_ds)}\n",
    "    ----------------------------------\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caching the dataset\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and rescale the images\n",
    "#resize_and_rescale = tf.keras.Sequential([\n",
    "#  tf.keras.layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "#  tf.keras.layers.Rescaling(1./255),\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that the images are rescaled\n",
    "#normalized_ds = train_ds.map(lambda x, y: (resize_and_rescale(x), y))\n",
    "#image_batch, labels_batch = next(iter(normalized_ds))\n",
    "#first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "#print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras api \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.1),\n",
    "  tf.keras.layers.RandomContrast(0.2),\n",
    "  tf.keras.layers.RandomZoom(0.2),\n",
    "  tf.keras.layers.RandomBrightness(factor=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = train_ds.map(\n",
    "#    lambda x, y: (data_augmentation(x, training=True), y)\n",
    "#).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "main_folder = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_counts = {}\n",
    "\n",
    "# Iterate through each subfolder (era)\n",
    "for era_folder in os.listdir(main_folder):\n",
    "    era_path = os.path.join(main_folder, era_folder)\n",
    "    if os.path.isdir(era_path):\n",
    "        # Count the number of images in the era folder\n",
    "        era_counts[era_folder] = len([filename for filename in os.listdir(era_path) if filename.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "# Create a pandas DataFrame from the era_counts dictionary\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Era': era_counts.keys(), 'Image Count': era_counts.values()})\n",
    "\n",
    "# Create the bar plot using seaborn\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "ax = sns.barplot(x='Era', y='Image Count', data=df, palette='flare')  # Choose a color palette you like\n",
    "for bar in range(len(ax.containers)):\n",
    "    ax.bar_label(ax.containers[bar])\n",
    "# Customize the plot\n",
    "plt.title('Data Imbalance in Taylor Swift Eras Tour Images', fontsize=16)\n",
    "plt.xlabel('Eras', fontsize=14)\n",
    "plt.ylabel('Number of Images', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_inverse_num_samples(num_of_classes, samples_per_classes, coeff=1):\n",
    "    \"\"\"\n",
    "    Get the inverse number of samples for each class.\n",
    "    Args:\n",
    "        num_of_classes (int): Number of classes in the dataset.\n",
    "        samples_per_classes (list): List of number of samples per class.\n",
    "        power (int, optional): Power of the inverse number of samples. Defaults to 1.\n",
    "    Returns:\n",
    "        list: List of inverse number of samples for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    inverse_num_samples = []\n",
    "    total_samples = sum(samples_per_classes)\n",
    "\n",
    "    for i in range(num_of_classes):\n",
    "        inverse_num_samples.append((total_samples / (num_of_classes * samples_per_classes[i])) * coeff)\n",
    "\n",
    "    return inverse_num_samples\n",
    "\n",
    "num_of_classes = 10\n",
    "samples_per_classes = [era_counts['1989'], era_counts['Acoustic'], era_counts['Fearless'], era_counts['Folkmore'], era_counts['Lover'], era_counts['Midnights'], era_counts['Red'], era_counts['Reputation'], era_counts['Speak'], era_counts['TTPD']] \n",
    "\n",
    "weighted_classes = get_weight_inverse_num_samples(num_of_classes, samples_per_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indexes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dict(zip(class_indexes, weighted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pretrained model ResNet50 to experiment if we can have further improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = tf.keras.applications.ResNet50(\n",
    "weights=\"imagenet\",\n",
    "include_top=False,\n",
    "input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used pretrained model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_base = tf.keras.applications.vgg16.VGG16(\n",
    "#weights=\"imagenet\",\n",
    "#include_top=False,\n",
    "#input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in conv_base.layers[:-12]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "#x = resize_and_rescale(x)\n",
    "\n",
    "x = tf.keras.applications.resnet.preprocess_input(x)\n",
    "#x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "\n",
    "x = conv_base(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(256)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(CLASSES, activation=\"softmax\", kernel_regularizer=l2(0.001))(x)\n",
    "#outputs = tf.keras.layers.Dense(CLASSES, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"saved_models/all_VGG16_models/best_model_weighted_RESNET50.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "lr_plateau = callbacks.ReduceLROnPlateau(factor=0.8, monitor=\"val_accuracy\", patience=5, verbose=1)\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=ES_EPOCHS)\n",
    "callbacks_list = [checkpoint, es, lr_plateau]\n",
    "#callbacks_list = [checkpoint, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"saved_models/all_VGG16_models/best_model_weighted_RESNET50.keras\"\n",
    "best_model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = best_model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc = history.history['accuracy']\n",
    "#val_acc = history.history['val_accuracy']\n",
    "\n",
    "#loss = history.history['loss']\n",
    "#val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPOCHS = 113\n",
    "\n",
    "#plt.figure(figsize=(8, 8))\n",
    "#plt.subplot(1, 2, 1)\n",
    "#plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "#plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.title('Training and Validation Accuracy')\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "#plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "#plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.title('Training and Validation Loss')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_y(dataset, model):\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "\n",
    "  for x, y in dataset:\n",
    "    y_true.append(y)\n",
    "    y_pred.append(tf.argmax(model.predict(x),axis = 1))\n",
    "    \n",
    "  y_pred = tf.concat(y_pred, axis=0)\n",
    "  y_true = tf.concat(y_true, axis=0)\n",
    "\n",
    "  return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_pred, y_true = create_list_y(test_ds, best_model)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASS_NAMES)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def read_file_as_img(file_path)-> np.ndarray:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = f.read()\n",
    "    image = np.array(Image.open(BytesIO(data)))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tensorflow model\n",
    "PROD_MODEL_PATH = \"saved_models/all_VGG16_models/best_model_weighted_RESNET50.keras\"\n",
    "\n",
    "PROD_MODEL = tf.keras.models.load_model(PROD_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_file_as_img(\"images/taylor-swift-eras-tour-032023-3-1-cab011d6ac7243e68b93d383134ad604.jpg\")\n",
    "\n",
    "# Resize the image to 256x256\n",
    "img = tf.image.resize(img, [256, 256]) \n",
    "\n",
    "# Predict the image classification\n",
    "img_batch = np.expand_dims(img, 0)\n",
    "predictions = PROD_MODEL.predict(img_batch)\n",
    "\n",
    "predicted_class = CLASS_NAMES[np.argmax(predictions[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
